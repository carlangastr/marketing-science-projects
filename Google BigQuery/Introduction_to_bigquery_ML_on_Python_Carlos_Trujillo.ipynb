{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to bigquery ML on Python | Carlos Trujillo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgcGDFlAQLFeann0qTB3gL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlangastr/marketing-science-projects/blob/main/Introduction_to_bigquery_ML_on_Python_Carlos_Trujillo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_EnA2wB2m8K"
      },
      "source": [
        "## **INTRODUCTION TO BIGQUERY ML USING PYTHON.**\n",
        "`Developed by: Carlos Trujillo`\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Github: https://github.com/carlangastr\n",
        "\n",
        "Linkedin profile: https://www.linkedin.com/in/carlangastr/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGGT6ypWNMme"
      },
      "source": [
        "This tutorial introduces data scientists to <strong>BigQuery ML</strong> and is based on the <a href=\"https://cloud.google.com/bigquery-ml/docs/introduction?hl=es-419\">official documentation tutorial</a>. BigQuery ML enables users to create and execute machine learning models in BigQuery using SQL queries.\n",
        "\n",
        "In this tutorial, i will use the API REST of Google on Python and one of the bigquery public datasets to make model to predict the sessions in a website, <strong>based on the information of Google Analytics.</strong>\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXS6z8kpT8na"
      },
      "source": [
        "### **STEP ONE: Setup and create your dataset**\n",
        "\n",
        "\n",
        "Create a BigQuery dataset to store your ML model. Being a platform within BigQuery, datasets can host data and models.\n",
        "\n",
        "Using the right hand parameters, you can easily change the values ​​and run the code, using your credentials and project id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNvpP8i_VBQs"
      },
      "source": [
        "#Obviously we need to import our libraries\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "from google.cloud.bigquery import magics\n",
        "import os\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AytTUTWAk6kU",
        "outputId": "a8deeb5c-6ce3-4b4c-b07e-5f667522e0c1"
      },
      "source": [
        "file_json = 'credentials.json' #@param {type:\"string\"}\n",
        "project_id = '' #@param {type:\"string\"}\n",
        "credential = service_account.Credentials.from_service_account_file(file_json)\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = file_json\n",
        "\n",
        "client = bigquery.Client(credentials = credential, project = project_id)\n",
        "\n",
        "name_of_dataset = '' #@param {type:\"string\"}\n",
        "\n",
        "dataset = client.create_dataset(name_of_dataset, exists_ok=True) \n",
        "print('dataset created')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdcFxbhLlAbQ"
      },
      "source": [
        "#Load magic commands\n",
        "%load_ext google.cloud.bigquery"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRATtyXK2op1"
      },
      "source": [
        "After loading the magic commands on our notebook, we only need to use '%% bigquery' to execute our queries.\n",
        "\n",
        "Keep in mind that this property is valid only in jupyter notebooks.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **STEP THREE: Create and train your model**\n",
        "\n",
        "\n",
        "Creating the model within BigQuery ML is quite simple, just use the standard syntax and give the model the parameters to be created.\n",
        "\n",
        "BigQuery ML does not offer the possibility of moving the hyperparameters as much, as you could do in Keras or Pytorch. These models are already ordered parts, similar to sklearn,\n",
        "powerful but without much possibility of change.\n",
        "\n",
        "<a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create\">You can see more about the documentation of CREATE MODEL here.</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URnVX78nlAdt"
      },
      "source": [
        "%%bigquery\n",
        "CREATE MODEL IF NOT EXISTS `bqml_tutorial.arima_model`\n",
        "OPTIONS(model_type = 'ARIMA', \n",
        "time_series_data_col='sessions', \n",
        "time_series_timestamp_col='date',\n",
        "data_frequency='DAILY'\n",
        "#holiday_region='US'\n",
        ") AS\n",
        "\n",
        "SELECT PARSE_TIMESTAMP(\"%Y-%m-%d\", SUBSTR(CAST(date AS STRING), 0,10)) date, sum(sessions) sessions\n",
        "FROM `project_id.dataset_name.table_name` -- ¡Replace the data here! \n",
        "where date <= '2020-12-31'\n",
        "AND country = 'chile'\n",
        "GROUP by 1\n",
        "ORDER by 1 DESC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ9k1P3Zh7d4"
      },
      "source": [
        "After training our model, we can request its statistics to understand its effectiveness.\n",
        "\n",
        "The results of training, coefficients and evaluation can be saved in other additional tables within our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCMr1SsOlAf0"
      },
      "source": [
        "%%bigquery\n",
        "\n",
        "CREATE OR REPLACE TABLE `bqml_tutorial.arima_results_traing` AS (\u000bSELECT\n",
        " *\n",
        "FROM\n",
        "ML.TRAINING_INFO(MODEL `bqml_tutorial.arima_model`)\n",
        ");\n",
        "\n",
        "CREATE OR REPLACE TABLE `bqml_tutorial.arima_results_coeff` AS (\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.ARIMA_COEFFICIENTS(MODEL `bqml_tutorial.arima_model`)\n",
        ");\n",
        "\n",
        "CREATE OR REPLACE TABLE `bqml_tutorial.arima_results_evaluate` AS (\n",
        "SELECT\n",
        " *\n",
        "FROM\n",
        " ML.EVALUATE(MODEL `bqml_tutorial.arima_model`)\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvM7uqk-2qhd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### **STEP FOUR: Doing predictions**\n",
        "\n",
        "After evaluating the effectiveness of our model, we are ready to make predictions.\n",
        "\n",
        "In this case we can use `ML.FORECAST` to ask BigQuery ML for a prediction.\n",
        "\n",
        "In this case we use `FORCAST` but depending on the model we could use `PREDICT`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIxj6OUtlAiJ"
      },
      "source": [
        "%%bigquery\n",
        "SELECT \n",
        "  *\n",
        " FROM ML.FORECAST(MODEL `bqml_tutorial.arima_model`, STRUCT(90 AS horizon, 0.8 AS confidence_level))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm8goMGulbXu"
      },
      "source": [
        "If you are not using a jupyter notebook, you can use the pandas `read.gbq ()` function to run the query and get a result dataframe.\n",
        "\n",
        "Applying this will give you the ability to visualize the results through matplot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaAGkoUNlAkZ"
      },
      "source": [
        "query_statement = \"\"\"\n",
        "WITH actuals AS (\n",
        "SELECT \n",
        "  PARSE_TIMESTAMP(\"%Y-%m-%d\", \n",
        "  SUBSTR(CAST(date AS STRING), 0,10)) date, \n",
        "  sum(sessions) sessions\n",
        "FROM `project_id.dataset_name.table_name`\n",
        "where date > '2020-12-31'\n",
        "AND country = 'chile'\n",
        "GROUP BY 1)\n",
        "\n",
        "SELECT \n",
        " forecast_timestamp,\n",
        " SUM(sessions) AS actuals,\n",
        " SUM(prediction_interval_lower_bound) AS lower_value,\n",
        " SUM(forecast_value) AS middle_value,\n",
        " SUM(prediction_interval_upper_bound) AS upper_value\n",
        " FROM ML.FORECAST(MODEL `bqml_tutorial.arima_model`, \n",
        "\tSTRUCT(90 AS horizon, 0.9 AS confidence_level)) as ML\n",
        " LEFT JOIN actuals AS ac \n",
        " ON forecast_timestamp = ac.date\n",
        " GROUP BY 1\n",
        "\"\"\"\n",
        "\n",
        "dataframe = pd.read_gbq(query)\n",
        "\n",
        "\n",
        "dataframe.plot(x ='forecast_timestamp’, \n",
        "\t\ty=['actuals', 'upper_value', 'middle_value', 'lower_value’], \n",
        "\t\tkind = 'line')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmfGdzj2rFe"
      },
      "source": [
        "If the only thing you are looking for is to execute a query without having to write it to a dataframe, you can directly use the `QUERY` function from the BigQuery library.\n",
        "\n",
        "\n",
        "You can combine this with native python functions to standardize how you write queries and automate the creation of your models.\n",
        "\n",
        "In the section below I leave you a small example: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbDMJ2hlAm4"
      },
      "source": [
        "##This is an example\n",
        "\n",
        "query_create_model = \"\"\"\n",
        "\n",
        "CREATE MODEL IF NOT EXISTS `{dataset_name}.{model_name}`\n",
        "OPTIONS(model_type='{ml_model}') AS\n",
        "SELECT\n",
        "  {select_condition}\n",
        "FROM\n",
        "  `{project_id}.{dataset_name}.{table_name}`\n",
        "WHERE\n",
        "  {where_condition}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query_create_model.format(\n",
        "                                                    dataset_name = 'your',\n",
        "                                                    model_name = 'parameters',\n",
        "                                                   ml_model = 'here'))\n",
        "print(query_job.result())\n",
        "\n",
        "\n",
        "query_create_model.format()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}